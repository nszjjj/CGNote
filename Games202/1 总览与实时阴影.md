# 引

> Real Time是一种Trade Off：高质量与实时之间的权衡

Real Time意味着：

- Speed：FPS>30（VR/AR要求>90FPS）

- Interactivity：每帧都要快速生成

High Quality意味着：

- Realism：物理正确/计算量大/需要更多耗时

- Dependability：

实时渲染就是对离线渲染的近似、简化和各种Trick

Science!=Technology

Science=Knowledge

- 实时渲染工业界领先学术界

- 预计算：空间换时间

> 作业0~5，以GLSL为主，加Pass就是JS添加，粗暴来说像是一个教写着色器的

里程碑：

- Interactive Ray Tracing：CUDA+OptiX

# Recap of CG Basics

> 我不到啊，这是lecture2里面的东西

# Real-Time Shadows

## 总览

依赖于Shadow Mapping（后文缩写SM）的技术

关于Shadow Mapping

- 2Pass（Light Pass + Camera Pass)

- Image Space Algorithm（自遮挡问题/走样/锯齿）

- 是早期离线渲染阴影绘制手法

- 本质是Light视角的Depth值

- 精度受SM分辨率影响

为了解决自遮挡和走样等问题，人们后续提出了多种改良技术，如Percentage-Closer Filtering (PCF)、Variance Shadow Mapping (VSM)、Cascaded Shadow Mapping (CSM) 等。

## 失真问题

### 自遮挡

> 传统的SM绘制阴影的问题：自遮挡和走样

这个问题在LearnOpenGL里叫归为一种阴影失真，我直接把他的图拿过来了，因为202的图不是很清晰：

<img title="" src="file:///D:/CGNote/Games202/img/shadow_mapping_shadows.png" alt="阴影自遮挡效果示意" data-align="center">

然后问题在于，下面这种情况，当SM分辨率不够的时候，一大块范围内的深度（下面紫色示意的范围）都被SM的同一个像素记录。但是在Camera Pass处理的时候，他发现某些片元到光源的距离（或者Z值）可能大于SM里所记录的值（对应紫色范围靠右端的情况），反之也有到光源距离小于SM里所记录的值的情况，对应紫色范围靠左端的情况。

<img src="file:///D:/CGNote/Games202/img/sm_1.png" title="" alt="阴影自遮挡的原理示意" data-align="center">

显然自上往下照的时候，这个问题出现的最小，光源方向与光照表面法线越接近90°，出现问题的可能性越大、效果越明显。

解决方法1：阴影偏移（shadow bias）。

其中，偏移不一定是固定值。可以调整为光源方向与光照表面法线越接近90°，这个值越大，反之则小，这样更加合理。

不过这就产生了另一个问题：Shadow Bias过于夸张的时候会导致阴影相对实际物体位置的偏移，此类失真问题称之为悬浮(Peter Panning)，或者说detached shadow。完美的解决方法并不存在，一般就是找到一个效果适中的值。

解决方法2：Second-depth Shadow Mapping

对于每个像素，不仅存储其到光源的距离（深度），还存储其后面第二个可见表面的距离，最终的距离（深度）采用二者的平均值。其技术关键在于确定第二个表面的深度的方法。这种方法计算开销再度增加，

应用解决方法2的条件十分苛刻，以至于几乎无法使用：

- 模型必须是watertight（水密）的，即封闭的、没有孔洞的

- 计算second-depth几乎是要做GPU排序，至少是O(n)的复杂度

但是：

1. 如果是单面的地板，second-depth记录为无限大就行

2. <mark>实时渲染不相信时间复杂度</mark>（只相信绝对的速度）

3. 大部分效果，开销要在1ms内

### 走样

我还是拿LearnOpenGL的图做示意，这主要源自SM的分辨率不够：

<img src="file:///D:/CGNote/Games202/img/shadow_mapping_zoom.png" title="" alt="阴影的走样示意" data-align="center">

解决方法：

1. CSM（工业界做法）

2. 动态分辨率的SM

## 微积分不等式

> 实时渲染中关心近似相等，而不关心不等。

在极限情况下，一些不等式可以达到近似相等，这也就给不等式提供了使用场合（当作约等式使用）

$$
\int_\Omega f(x)g(x)dx \approx \frac{\int_\Omega f(x)dx}{\int_\Omega dx}·\int_\Omega g(x)dx
$$

其中分母表示归一化的常数。

使用场合（哪些情况下结果较为准确）：

1. small spport：在实际的积分范围较小的情况下

2. smooth integrand：在g(x)min、max差别不大的情况下

（其实就是说某些项如果接近常数就可以提出来）

使用这个公式化简渲染方程，可以得到下面的推导式：

<img src="file:///D:/CGNote/Games202/img/rendering_quation_approximation.png" title="" alt="渲染方程的近似" data-align="center">

于是就把渲染过程分解为：做Shading，然后乘上visibility。

什么时候渲染方程符合使用条件呢？

1. small spport：点或者方向光照，此时积分范围就一个点

2. smooth integrand：指的是被积函数$g(x)$，这又要分为两部分，一部分是描述光源性质的$L_i$，另一部分是描述照射点性质的BRDF。具体来说就是常量辐照度的区域光照和diffuse BRDF（glossy BRDF就是一个反例） 

反过来说，对于面光源+glossy BRDF，SM做阴影效果就不是很好

## 软阴影与PCF

对于面光源，在阴影的边界处看向光源，其实是有一部分光源被遮挡的，所以并不是绝对地“在阴影中”或者“不在阴影中”两种情况。软阴影就针对“部分遮挡”的区域，做出渐变效果的技术

> 太阳是一种典型的面光源。

PCF（Percentage-Closer Filtering），即百分比更近滤波或比例最近邻滤波。是一种用于改善阴影贴图 (Shadow Mapping) 质量的技术，主要用于减少阴影边缘的锯齿状瑕疵 (aliasing)。对，本来不是做软阴影的

> Filtering（滤波）是根据一定的规则对像素值进行加权平均，核心思想是使用一个滤波器（filter kernel）对图像数据进行卷积运算，一般最终效果就是模糊

1. 不是对已经由锯齿的阴影进行Filter（是对比较结果Filter）

2. 不是对SM进行Filter（SM表示Z值或者深度，Filter没意义）

PCF是在计算某片元A阴影的时候，取用该片元周围区域被遮挡的程度来做阴影的最终值。也就是使用一个小方形核来采样SM，对于每个采样点均和<mark>片元A</mark>（或者说shadow point）的深度进行比较，比较的结果<u>是0或者1</u>。周围区域均做此操作所得到的多个值，加权取平均后得到的是一个介于 0 到 1 之间的阴影因子，0 表示完全处于光照中，1 表示完全处于阴影中。

缺点

- 需要对SM进行多次采样，会增加一定的计算开销

- 可能会导致阴影边缘过于模糊，失去一些细节（这和filter的大小有关）

流程：

1. light pass：渲染各个光源的SM（shadow map）

2. camera pass：使用SM计算，伪代码如下

```csharp
foreach(var fragment in View){
    foreach(var light in LightStack){
        // 计算片元到光源的距离a
        // 对片元在Shadow Map的位置周围做filter（依次深度比较取均值）算出阴影因子
    }
}
```

用Z值或者距离比较都行，但是要一致计算的是片元到光源的距离，那就要和距离比。（Z值经过透视除法之后是非线性的）

如果直接比较得出“是”或者“不是”在阴影中，则效果过于生硬。PCF不直接通过SM非黑即白地判断某个像素是否在阴影内，而是为一个像素多次采样SM，计算一个遮挡百分比，这涉及到的关键在于：

- 采样点的确定

- 采样点的加权平均（可选）

- 遮挡百分比的计算与最终阴影颜色的计算

> 是不是有一种计算AO的感觉

## PCSS

### 基本原理

PCSS，即Percentage-Closer Soft Shadows（百分比更近的软阴影），是一种用于渲染软阴影的算法，由Nvidia在2005年提出。主要用于处理面光源（Area Light）产生的软阴影。 不同于点光源，面光源具有面积，因此产生的阴影具有半影（penumbra）区域，边缘更柔和。（point和directional light应当产生硬阴影的）

论文本体：[Percentage-Closer Soft Shadows](https://developer.download.nvidia.com/shaderlibrary/docs/shadow_PCSS.pdf)

演示PPT：[PCSS PowerPoint Presentation](https://download.nvidia.com/developer/presentations/2005/SIGGRAPH/Percentage_Closer_Soft_Shadows.pdf)

特点：

- 要绘制两遍（这也是缺点，计算成本高）

- 质量好，更真实

半影区（过渡区域）即下图中$W_{Penumbra}$所标识的部分：

<img src="file:///D:/CGNote/Games202/img/lecture3_1.png" title="" alt="半影区示意" data-align="center">

这部分区域只能得到面光源的一部分光照，这个区域越大，影子越“软”。当光源退化至只有一个点，效果就与常见的硬阴影无异了。

这段区域的大小与产生影子的Blocker到光源与接收影子的面的距离有关系，具体公式可以按相似三角形推知：

$$
W_{Penumbra} = (d_{Receiver} - d_{Blocker})·W_{Light}/d_{Blocker}
$$

Filter的大小取决于两方面：

- 光源的面积

- Blocker到光源的距离

在光源无法改变的情况下，需要依靠上面的$d_{Blocker}$来确定Filter的Size。由于遮挡物形状通常是多样的，因此会为某个点取其临近区域的平均值作为该点的$d_{Blocker}$值，并由此值确定Filter的Size。这个计算average blocker depth的过程称之为Blocker Search。

做Blocker Search的范围与$d_{Receiver}$有反比例关系：Light离得远则范围小，反之则大

在这一步完成后，相当于已知滤波核大小，接下来就是经典的PCF了。

不过这个过程的计算开销仍很大，所以还是需要各种Trick简化这个过程，主要是减少采样次数。

### 滤波与PCSS公式

滤波的数学公式表达是这样的：

$$
[w * f](p) = \sum _{q \in \mathcal{N}(p)}w(p,q)f(x, y)
$$

其中

- w是一个权重函数或称之为滤波器核，在这里通常是一个与$p$和$q$之间距离有关的函数

- f代表输入信号或图像

- p是要处理的点

- q \in \mathcal{N}(p) 表示 q 属于 p 的邻域

- w(p,q)代表 p 和 q 之间的权重

- f(x, y)表示在点 q 处的信号值

在PCSS中，则是下述公式

$$
V(x) = \sum _{q \in \mathcal{N}(p)}w(p,q)·\chi^+[D_{SM}(q)-D_{scene}(x)]
$$

- $\chi^+$是符号函数，如果函数变量大于0则结果为1，小于则为0

- $w$处理的是符号函数$\chi^+$的结果

$$
V(x) \neq \sum _{q \in \mathcal{N}(p)}\chi^+\{[w(p,q)·D_{SM}(q)]-D_{scene}(x)\}
$$

- 上述右侧意思是对shadow map进行filter，这是不对的

$$
V(x) \neq \sum _{y \in \mathcal{N}(x)}w(x,y)V(y)
$$

- 也不是去对渲染出来的有锯齿的硬阴影做模糊

### 性能分析与实现

在SM的某点邻域查找值参与计算是一件开销不小的事情，因为数量级不小。

不过可以稀疏采样，但是稀疏采样的问题是结果噪声，那就得再去图像空间做一遍降噪。

降噪的话有两个方向都可以实现：

- 图像域（空间域）

- 时间累积（TAA）

实现（三步）：

1. Block Research：获取一个区域内的average blocker depth

2. Penumbra estimation：根据average blocker depth选取下一步PCF的Filter kernel size

3. Percentage Closer Filtering：经典PCF，无需多言

## VSSM

VSSM (Variance Shadow Mapping) 是一种改进的阴影映射技术，旨在解决传统阴影映射中出现的阴影边缘锯齿和自遮挡问题。它通过在阴影贴图中存储每个像素的深度值及其方差来实现更精确的阴影计算。

### 推导

<mark>问题的起源</mark>：在PCSS中的第三步，也就是PCF的时候，其求解的本质是，我当前这个片元的depth在周围这个范围内能排进前百分之多少。因为邻域范围内每次比较结果都是0或者1（还记得上面公式中的$\chi^+$吗），然后求平均的话，相当于是一个“排进前百分之多少”的问题。

<mark>通过直方图估计百分比</mark>：依次比较判断处于前百分之多少的操作，可以利用直方图完成。将距离分为多个小区间，则可以通过直方图查出处于这个区间的Depth的数量。

<mark>从直方图退化为正态分布</mark>：如果近似（不那么精确）地来看，可以当成正态分布处理，因此就不需要直方图了。为了定义一个正态分布的PDF$f(x;μ, σ)$，需要知道均值和方差。反过来说，快速得到一个区域的均值和方差，就能去估计这个百分比。通过正态分布函数的CDF来查询即可（Cumulative Distribution Function，累积分布函数，就是国内教材常写的大写$F$，对于连续型随机变量CDF求导得到的就是PDF）

<mark>快速获取范围均值</mark>：通过Hardware MIPMAPing查找。但是MIPMAP只能做正方形区域的查询。但是实际应用时查询的区域可能不是正方形，为了获取矩形区域的查询，需要使用Sum Area Table，这就是二维形式的前缀和。

（我一看这个问题，啪的一下，很快啊，我就想到了前缀数组，这就是刷leetcode给我带来的自信）

<mark>快速获取范围方差</mark>：利用公式$Var(X) = E(X^2)-E^2(X)$，以额外存储空间的代价（空间换时间），存$depth^2$。当然其实就是再生成原SM的同时，顺手写到它的另一个通道里就行。对于通用Gaussian PDF，通常做法是打表，预生成出来，叫做Error Function，误差函数，`erf(x)`。该函数有数值解，无解析解。

<mark>切比雪夫不等式</mark>：切比雪夫不等式作为一种概率工具，能够在已知期望和方差的情况下（对任意分布）求得随机变量$x$超过某个值的概率，当然查询的变量t必须大于均值。当然在rtr中会当成约等于用。

$$
P(X \ge t) \le p_{max}(t) \equiv \frac{\sigma^2}{\sigma^2+(t-\mu)^2}
$$

然后这就得到了，有百分之多少的深度不大于查询的$x$，当然有多少大于也是显而易见的了。有多少深度小于查询的$x$则意味被挡住的（不可见的）有百分之多少。

上述操作把其中一些操作换成了$O(1)$的，但是仍有些问题没解决，即在step 1里，我们要算的是filter范围内depth小于正在处理的位置的那些depth的平均值，而非filter范围内全体。但是观察到有如下性质：

$$
\frac{N_1}N z_{unocc} + \frac{N_2}N z_{occ}=z_{avg}
$$

即未被遮挡部分的数目$N_1$、未被遮挡部分的平均值$z_{unocc}$、遮挡部分的数目$N_2$、遮挡部分的平均值$z_{occ}$和总数$N$之间的关系。其中$N_1/N$恰是未被遮挡的元素占总体的比例，而这恰恰也能使用切比雪夫解决$p(x>t)$。$N_2/N$则是$1-P(x>t)$

而$z_{unocc}$则假设深度和当前shading point深度一致

### 问题

vssm在什么情况下不对？在不符合假设前提的情况下不对。比如说如果不符合正态分布就不对，这导致结果偏暗或者偏亮（俗称漏光），因为估计到的能遮挡住shading point的比例可能明显偏离实际值。偏暗在视觉上是可以接受的，但是偏亮并非如此

## MSP

> moment shadow mapping

VSSM使用方差，属于二阶矩。MSP使用更高阶的矩去描述。$m$阶矩可以描述具有$m/2$个step的函数，这类似于某种展开。

<img src="file:///D:/CGNote/Games202/img/lecture4_1.png" title="" alt="高阶矩和CDF示意" data-align="center">

通常情况下4阶矩已经够了。但是由高阶矩推出拟合的CDF也很费劲。

# 附录

## 辐射度方程

辐射度（Radiosity，符号$J_e$，单位$W/m^2$）

$$
Radiosity = emitted \: energy + reflect \: energy
$$

即由物体本身辐射出的能量+反射来自其他物体的能量组成，遵循能量守恒定律

- 辐射度≠辐射强度

计算机研究的光学属于几何光学，不关注如干涉衍射之类的定律

## 渲染方程

光也属于辐射的范畴，将辐射度方程迁移到光照这种情形下：

$$
L_o=L_e+L_r
$$

然后最终形式就是这样的：

$$
L_o(x, \omega_o) = L_e(x, \omega_r) + \int_{\Omega} f_r(x, \omega_i, \omega_r) L_i(x, \omega_i) \cos \theta_i \, d\omega_i
$$

$L_o(x, ω_o)$关注从点$x$出射的光线，并分解为两部分：自发光和反射光。

自发光部分主要受物体材质影响。完全不发光材质，例如大多数常见的物体，这项恒为0。能够自发光的材质则又要分为漫反射和方向性两种做讨论处理。

反射光部分通过积分计算所有入射方向的光线贡献，并考虑了 BRDF、入射角余弦和微分立体角等因素。

关于反射光部分：

$f_r(x, \omega_i, \omega_r)$就是BRDF。

什么是$\int_{\Omega} d\omega_i$？有时候这个也写作$\int_{\Omega^+}d\omega_i$，表示这个积分是在半球空间 Ω 上进行的。更准确地说，是在表面法线方向上方的半球形立体角上进行积分。

即：对表面点$x$上方半球空间$\Omega$中的所有入射方向$ωᵢ $进行积分，累加所有入射光线对该点反射光的贡献。 这个积分的结果就是从表面点$x$出射到指定方向$ω₀$的反射光线强度$L_r(x, ω_o)$。

$L_i(x, ω_i)$则是入射辐射亮度，即到达表面点$x$，来自方向$ωᵢ$的光线强度。它决定了有多少光线可以被反射。该项可能受多方面影响，例如光源的强度、距离、光线的衰减以及其他物体的遮挡等因素
